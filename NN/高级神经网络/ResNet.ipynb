{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import math \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean = [x/255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x/255 for x in [63.0, 62.1, 66.7]]\n",
    "n_train_samples = 5000\n",
    "\n",
    "# 使用数据增强\n",
    "train_set = dsets.CIFAR10(root='./data', train=True, transform=transforms.Compose([ \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "]), download=True)\n",
    "train_dl = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "train_set.data = train_set.data[:n_train_samples]\n",
    "train_set.targets = train_set.targets[:n_train_samples]\n",
    "\n",
    "# 测试集也一样\n",
    "test_set = dsets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "]), download=True)\n",
    "test_dl = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练的辅助函数\n",
    "def eval(model,criterion,dataloader):\n",
    "    model.eval()\n",
    "    loss, accuracy = 0., 0.\n",
    "    \n",
    "    # torch.no_grad()表示在计算图中不构建梯度计算\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            logits = model(batch_x)\n",
    "            error = criterion(logits, batch_y)\n",
    "            loss += error.item()\n",
    "            \n",
    "            probs, pred_y = logits.data.max(dim=1)\n",
    "            accuracy += (pred_y == batch_y.data).float().sum()/batch_y.size(0)\n",
    "            \n",
    "        loss /= len(dataloader)\n",
    "        accuracy = accuracy*100.0/len(dataloader)\n",
    "        return loss, accuracy\n",
    "    \n",
    "def train_epoch(model, criterion, optimizer, dataloader):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_x)\n",
    "        error = criterion(logits, batch_y)\n",
    "        error.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=1):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.stride = stride\n",
    "        self.F = nn.Sequential(nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1),\n",
    "                                    nn.BatchNorm2d(out_channels),nn.ReLU(),\n",
    "                                    nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1),\n",
    "                                    nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        if self.stride != 1:\n",
    "            self.identity= nn.Sequential(nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride),\n",
    "                                            nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            \n",
    "    def forward(self,x):\n",
    "        if self.stride == 1:\n",
    "            x = self.F(x)+x\n",
    "        else:\n",
    "            x = self.F(x)+self.identity(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32, 32, 32])\n",
      "torch.Size([5, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "rbk1 = ResidualBlock(32,32)\n",
    "rbk2 = ResidualBlock(32,64,2)\n",
    "\n",
    "x = torch.rand(5,32,32,32)\n",
    "y1 = rbk1(x)\n",
    "y2 = rbk2(x)\n",
    "\n",
    "print(y1.size())\n",
    "print(y2.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.feature = nn.Sequential(nn.Conv2d(3,16,kernel_size=3,padding=1),nn.BatchNorm2d(16),nn.ReLU(),\n",
    "                                    ResidualBlock(16,16),ResidualBlock(16,16),ResidualBlock(16,16),\n",
    "                                    ResidualBlock(16,32,2),ResidualBlock(32,32),ResidualBlock(32,32),\n",
    "                                    ResidualBlock(32,64,2),ResidualBlock(64,64),ResidualBlock(64,64),\n",
    "                                    nn.AvgPool2d(8)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.feature(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "[  1/50, 114 seconds] |\t tr_err: 2.0e+00, tr_acc: 23.96 |\t te_err: 2.0e+00, te_acc: 25.29\n",
      "[  2/50, 114 seconds] |\t tr_err: 1.8e+00, tr_acc: 31.98 |\t te_err: 1.8e+00, te_acc: 33.21\n",
      "[  3/50, 114 seconds] |\t tr_err: 1.7e+00, tr_acc: 34.10 |\t te_err: 1.8e+00, te_acc: 33.64\n",
      "[  4/50, 114 seconds] |\t tr_err: 1.8e+00, tr_acc: 31.40 |\t te_err: 1.9e+00, te_acc: 31.92\n",
      "[  5/50, 114 seconds] |\t tr_err: 1.6e+00, tr_acc: 41.42 |\t te_err: 1.6e+00, te_acc: 40.67\n",
      "[  6/50, 114 seconds] |\t tr_err: 1.7e+00, tr_acc: 37.78 |\t te_err: 1.8e+00, te_acc: 37.64\n",
      "[  7/50, 114 seconds] |\t tr_err: 1.6e+00, tr_acc: 41.34 |\t te_err: 1.6e+00, te_acc: 41.16\n",
      "[  8/50, 114 seconds] |\t tr_err: 1.6e+00, tr_acc: 43.48 |\t te_err: 1.6e+00, te_acc: 41.72\n",
      "[  9/50, 114 seconds] |\t tr_err: 1.5e+00, tr_acc: 42.16 |\t te_err: 1.6e+00, te_acc: 40.89\n",
      "[ 10/50, 114 seconds] |\t tr_err: 1.4e+00, tr_acc: 49.88 |\t te_err: 1.4e+00, te_acc: 48.34\n",
      "[ 11/50, 114 seconds] |\t tr_err: 1.7e+00, tr_acc: 42.02 |\t te_err: 1.9e+00, te_acc: 39.72\n",
      "[ 12/50, 114 seconds] |\t tr_err: 1.4e+00, tr_acc: 50.44 |\t te_err: 1.4e+00, te_acc: 49.34\n",
      "[ 13/50, 113 seconds] |\t tr_err: 1.4e+00, tr_acc: 50.12 |\t te_err: 1.5e+00, te_acc: 47.62\n",
      "[ 14/50, 113 seconds] |\t tr_err: 1.3e+00, tr_acc: 54.82 |\t te_err: 1.4e+00, te_acc: 51.16\n",
      "[ 15/50, 114 seconds] |\t tr_err: 1.3e+00, tr_acc: 54.54 |\t te_err: 1.5e+00, te_acc: 49.23\n",
      "[ 16/50, 113 seconds] |\t tr_err: 1.2e+00, tr_acc: 56.88 |\t te_err: 1.3e+00, te_acc: 53.10\n",
      "[ 17/50, 114 seconds] |\t tr_err: 1.4e+00, tr_acc: 53.56 |\t te_err: 1.5e+00, te_acc: 50.25\n",
      "[ 18/50, 115 seconds] |\t tr_err: 1.1e+00, tr_acc: 60.68 |\t te_err: 1.3e+00, te_acc: 54.90\n",
      "[ 19/50, 115 seconds] |\t tr_err: 1.1e+00, tr_acc: 60.84 |\t te_err: 1.3e+00, te_acc: 53.34\n",
      "[ 20/50, 114 seconds] |\t tr_err: 1.1e+00, tr_acc: 60.62 |\t te_err: 1.4e+00, te_acc: 53.47\n",
      "[ 21/50, 115 seconds] |\t tr_err: 1.0e+00, tr_acc: 62.22 |\t te_err: 1.3e+00, te_acc: 57.48\n",
      "[ 22/50, 115 seconds] |\t tr_err: 1.1e+00, tr_acc: 61.88 |\t te_err: 1.3e+00, te_acc: 55.33\n",
      "[ 23/50, 115 seconds] |\t tr_err: 1.1e+00, tr_acc: 62.08 |\t te_err: 1.4e+00, te_acc: 55.49\n",
      "[ 24/50, 115 seconds] |\t tr_err: 1.1e+00, tr_acc: 61.06 |\t te_err: 1.4e+00, te_acc: 55.58\n",
      "[ 25/50, 115 seconds] |\t tr_err: 9.5e-01, tr_acc: 66.54 |\t te_err: 1.3e+00, te_acc: 58.57\n",
      "[ 26/50, 116 seconds] |\t tr_err: 9.1e-01, tr_acc: 68.42 |\t te_err: 1.2e+00, te_acc: 60.62\n",
      "[ 27/50, 115 seconds] |\t tr_err: 9.1e-01, tr_acc: 67.76 |\t te_err: 1.2e+00, te_acc: 60.35\n",
      "[ 28/50, 115 seconds] |\t tr_err: 9.5e-01, tr_acc: 66.08 |\t te_err: 1.3e+00, te_acc: 58.33\n",
      "[ 29/50, 115 seconds] |\t tr_err: 1.0e+00, tr_acc: 64.82 |\t te_err: 1.3e+00, te_acc: 57.95\n",
      "[ 30/50, 114 seconds] |\t tr_err: 8.6e-01, tr_acc: 69.76 |\t te_err: 1.2e+00, te_acc: 61.44\n",
      "[ 31/50, 114 seconds] |\t tr_err: 8.8e-01, tr_acc: 68.98 |\t te_err: 1.2e+00, te_acc: 60.40\n",
      "[ 32/50, 114 seconds] |\t tr_err: 9.1e-01, tr_acc: 67.40 |\t te_err: 1.3e+00, te_acc: 58.03\n",
      "[ 33/50, 114 seconds] |\t tr_err: 7.4e-01, tr_acc: 73.64 |\t te_err: 1.2e+00, te_acc: 63.36\n",
      "[ 34/50, 114 seconds] |\t tr_err: 8.6e-01, tr_acc: 69.36 |\t te_err: 1.2e+00, te_acc: 60.85\n",
      "[ 35/50, 114 seconds] |\t tr_err: 7.1e-01, tr_acc: 74.44 |\t te_err: 1.2e+00, te_acc: 62.81\n",
      "[ 36/50, 116 seconds] |\t tr_err: 7.1e-01, tr_acc: 75.22 |\t te_err: 1.2e+00, te_acc: 62.82\n",
      "[ 37/50, 114 seconds] |\t tr_err: 7.1e-01, tr_acc: 75.20 |\t te_err: 1.2e+00, te_acc: 63.36\n",
      "[ 38/50, 114 seconds] |\t tr_err: 6.2e-01, tr_acc: 78.26 |\t te_err: 1.1e+00, te_acc: 64.83\n",
      "[ 39/50, 114 seconds] |\t tr_err: 9.4e-01, tr_acc: 66.52 |\t te_err: 1.5e+00, te_acc: 56.67\n",
      "[ 40/50, 114 seconds] |\t tr_err: 4.9e-01, tr_acc: 83.30 |\t te_err: 9.7e-01, te_acc: 68.36\n",
      "[ 41/50, 115 seconds] |\t tr_err: 4.6e-01, tr_acc: 85.20 |\t te_err: 9.6e-01, te_acc: 68.51\n",
      "[ 42/50, 114 seconds] |\t tr_err: 4.3e-01, tr_acc: 85.40 |\t te_err: 9.9e-01, te_acc: 68.42\n",
      "[ 43/50, 115 seconds] |\t tr_err: 4.2e-01, tr_acc: 86.20 |\t te_err: 9.9e-01, te_acc: 68.63\n",
      "[ 44/50, 114 seconds] |\t tr_err: 4.2e-01, tr_acc: 86.32 |\t te_err: 9.9e-01, te_acc: 68.68\n",
      "[ 45/50, 114 seconds] |\t tr_err: 4.0e-01, tr_acc: 86.94 |\t te_err: 9.9e-01, te_acc: 68.80\n",
      "[ 46/50, 115 seconds] |\t tr_err: 3.9e-01, tr_acc: 87.08 |\t te_err: 1.0e+00, te_acc: 68.98\n",
      "[ 47/50, 114 seconds] |\t tr_err: 3.8e-01, tr_acc: 87.24 |\t te_err: 1.0e+00, te_acc: 68.81\n",
      "[ 48/50, 114 seconds] |\t tr_err: 3.8e-01, tr_acc: 87.44 |\t te_err: 1.0e+00, te_acc: 68.71\n",
      "[ 49/50, 115 seconds] |\t tr_err: 3.9e-01, tr_acc: 87.38 |\t te_err: 1.0e+00, te_acc: 68.53\n",
      "[ 50/50, 114 seconds] |\t tr_err: 3.7e-01, tr_acc: 87.94 |\t te_err: 1.0e+00, te_acc: 68.67\n"
     ]
    }
   ],
   "source": [
    "nepochs = 50\n",
    "\n",
    "net = ResNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(),\n",
    "                            lr=0.2,momentum=0.9,nesterov=True)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer,milestones=[40],gamma=0.1)\n",
    "learning_history = []\n",
    "\n",
    "print('Start Training')\n",
    "for epoch in range(nepochs):\n",
    "    since = time.time()\n",
    "    scheduler.step()\n",
    "    \n",
    "    current_lr = scheduler.get_lr()[0]\n",
    "    train_epoch(net,criterion,optimizer,train_dl)\n",
    "    tr_loss,tr_acc = eval(net,criterion,train_dl)\n",
    "    te_loss,te_acc = eval(net,criterion,test_dl)\n",
    "    now = time.time()\n",
    "    \n",
    "    learning_history.append([tr_loss,tr_acc,te_loss,te_acc])\n",
    "    print('[%3d/%d, %.0f seconds] |\\t tr_err: %.1e, tr_acc: %.2f |\\t te_err: %.1e, te_acc: %.2f' % (\n",
    "            epoch+1, nepochs, now-since, tr_loss, tr_acc, te_loss, te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
