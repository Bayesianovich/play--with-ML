{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "\n",
    "train_set = dsets.MNIST(root = '../data/mnist/',\n",
    "                        transform= trans.ToTensor(),\n",
    "                        train = True,\n",
    "                        download = True)\n",
    "test_set = dsets.MNIST(root = '../data/mnist/',\n",
    "                       transform = trans.ToTensor(),\n",
    "                       train = False,\n",
    "                       download = True)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_set,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = True,\n",
    "                                        num_workers = 4)\n",
    "test_dl = torch.utils.data.DataLoader(test_set,\n",
    "                                        batch_size = batch_size,\n",
    "                                        num_workers = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 28 *28\n",
    "N_CLASSES = 10\n",
    "nsamples = 60000\n",
    "lr = 5e-2\n",
    "nepochs = 20\n",
    "\n",
    "# 模型参数\n",
    "w = torch.rand((INPUT_DIM, N_CLASSES), requires_grad = True)\n",
    "b = torch.zeros((1,N_CLASSES), requires_grad = True)\n",
    "#定义优化算法 Optimizer\n",
    "optimizer = torch.optim.Adam([w,b], lr = lr)\n",
    "\n",
    "#选择学习率下降策略\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones = [10], gamma = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "def Cost(x,y):\n",
    "    pred_y = x.matmul(w) + b # (batch_size, N_CLASSES)\n",
    "    diff = pred_y - y\n",
    "    loss = diff.pow(2).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练所需的辅助函数\n",
    "- 用scatter将label转化成one-hot编码向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 0, 0, 1],\n",
      "        [2, 1, 0, 2, 1]])\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 1.],\n",
      "        [1., 1., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(3,5)\n",
    "index = torch.LongTensor([[1,2,0,0,1],[2,1,0,2,1]])\n",
    "x.scatter_(0, index, 1)\n",
    "\n",
    "print(index)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onehot(x,y):\n",
    "    n = x.size(0)\n",
    "    x = x.view(n,INPUT_DIM)\n",
    "    \n",
    "    y_onehot = torch.zeros(n, N_CLASSES)\n",
    "    y_onehot.scatter_(1, y.view(-1,1), 1)\n",
    "    y = y_onehot\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 4])\n",
      "tensor([[2],\n",
      "        [1],\n",
      "        [4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_classes = 5\n",
    "y = torch.tensor([2, 1, 4])\n",
    "print(y)\n",
    "y_onehot = torch.zeros(y.size(0), num_classes)\n",
    "print(y.view(-1,1))\n",
    "y_onehot.scatter_(1, y.view(-1,1), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 784])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,28,28)\n",
    "y = torch.LongTensor([[5],[1]])\n",
    "\n",
    "x,y = create_onehot(x,y)\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data_loader,optimizer):\n",
    "    error_total = 0\n",
    "    for batch_x, batch_y in data_loader:\n",
    "        x,y = create_onehot(batch_x, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = Cost(x,y)\n",
    "        loss.backward() # W.grad, b.grad\n",
    "        optimizer.step()\n",
    "        \n",
    "        error_total += loss.item()\n",
    "    return error_total / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cheng/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/Users/cheng/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:454: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Error: 46.6558, lr: 0.0500\n",
      "Epoch: 1, Train Error: 0.3239, lr: 0.0500\n",
      "Epoch: 2, Train Error: 0.1922, lr: 0.0500\n",
      "Epoch: 3, Train Error: 0.1313, lr: 0.0500\n",
      "Epoch: 4, Train Error: 0.0959, lr: 0.0500\n",
      "Epoch: 5, Train Error: 0.0743, lr: 0.0500\n",
      "Epoch: 6, Train Error: 0.0610, lr: 0.0500\n",
      "Epoch: 7, Train Error: 0.0528, lr: 0.0500\n",
      "Epoch: 8, Train Error: 0.0479, lr: 0.0500\n",
      "Epoch: 9, Train Error: 0.0439, lr: 0.0005\n",
      "Epoch: 10, Train Error: 0.0433, lr: 0.0050\n",
      "Epoch: 11, Train Error: 0.0429, lr: 0.0050\n",
      "Epoch: 12, Train Error: 0.0426, lr: 0.0050\n",
      "Epoch: 13, Train Error: 0.0423, lr: 0.0050\n",
      "Epoch: 14, Train Error: 0.0419, lr: 0.0050\n",
      "Epoch: 15, Train Error: 0.0416, lr: 0.0050\n",
      "Epoch: 16, Train Error: 0.0413, lr: 0.0050\n",
      "Epoch: 17, Train Error: 0.0410, lr: 0.0050\n",
      "Epoch: 18, Train Error: 0.0408, lr: 0.0050\n",
      "Epoch: 19, Train Error: 0.0406, lr: 0.0050\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nepochs):\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_lr()[0] \n",
    "    error_train = train_epoch(train_dl, optimizer)\n",
    "    print('Epoch: {}, Train Error: {:.4f}, lr: {:.4f}'.format(epoch, error_train, current_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    pred_y = x.matmul(w) + b\n",
    "    _,labels = pred_y.max(dim = 1)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价函数：计算准确率\n",
    "def evaluate(data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_x, batch_y in data_loader:\n",
    "        x,y = create_onehot(batch_x, batch_y)\n",
    "        pred_y = pred(x)\n",
    "        correct += (pred_y == batch_y).float().sum()\n",
    "        total += batch_x.size(0)\n",
    "    accuracy = 100.0*correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(85.4600)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X,y in test_dl:\n",
    "    break\n",
    "X = X.view(-1, 784)\n",
    "pred_y = pred(X)\n",
    "\n",
    "plt.figure(figsize = (20,5))\n",
    "for i in range(7):\n",
    "    plt.subplot(1,7,i+1)\n",
    "    img = X[i+50].squeeze().view(28,28).numpy()\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title(f'truth: {y[i+50]}, pred: {pred_y[i+50]}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as trans \n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "batch_size = 500\n",
    "INPUT_DIM = 28 *28\n",
    "N_CLASSES = 10\n",
    "nepochs = 20\n",
    "lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dsets.MNIST(root = '../data/mnist/',\n",
    "                        transform = trans.ToTensor(),\n",
    "                        train = True)\n",
    "test_set = dsets.MNIST(root = '../data/mnist/',\n",
    "                       transform = trans.ToTensor(),\n",
    "                          train = False)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_set,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = True\n",
    "                                        )\n",
    "test_dl = torch.utils.data.DataLoader(test_set,\n",
    "                                        batch_size = batch_size)\n",
    "\n",
    "                                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网络结构如下:\n",
      " LogisticRegression(\n",
      "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1,784)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "model = LogisticRegression(INPUT_DIM, N_CLASSES)\n",
    "print('网络结构如下:\\n',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones = [10], gamma = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,criterion, data_loader):\n",
    "    loss,accuracy = 0,0\n",
    "    for bx, by in data_loader:\n",
    "        logit = model(bx)\n",
    "        err = criterion(logit, by)\n",
    "        loss += err.item()\n",
    "        \n",
    "        \n",
    "        _,pred_y = logit.max(dim = 1)\n",
    "        accuracy += (pred_y.data == by).float().sum()/by.size(0)\n",
    "        \n",
    "    loss /= len(data_loader)\n",
    "    accuracy /= len(data_loader)\n",
    "    return loss, 100.0 * accuracy\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cheng/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.3386, Train Acc: 91.61%, Test Loss: 0.3589, Test Acc: 91.35%\n",
      "Epoch: 1, Train Loss: 0.3646, Train Acc: 90.38%, Test Loss: 0.4247, Test Acc: 89.61%\n",
      "Epoch: 2, Train Loss: 0.3319, Train Acc: 91.70%, Test Loss: 0.3961, Test Acc: 91.04%\n",
      "Epoch: 3, Train Loss: 0.3282, Train Acc: 91.90%, Test Loss: 0.4073, Test Acc: 91.44%\n",
      "Epoch: 4, Train Loss: 0.3936, Train Acc: 90.13%, Test Loss: 0.4565, Test Acc: 89.66%\n",
      "Epoch: 5, Train Loss: 0.3692, Train Acc: 91.32%, Test Loss: 0.4390, Test Acc: 90.86%\n",
      "Epoch: 6, Train Loss: 0.3626, Train Acc: 91.42%, Test Loss: 0.4819, Test Acc: 90.16%\n",
      "Epoch: 7, Train Loss: 0.3928, Train Acc: 90.36%, Test Loss: 0.5028, Test Acc: 89.56%\n",
      "Epoch: 8, Train Loss: 0.3460, Train Acc: 91.91%, Test Loss: 0.4620, Test Acc: 90.91%\n",
      "Epoch: 9, Train Loss: 0.2543, Train Acc: 93.60%, Test Loss: 0.3812, Test Acc: 91.92%\n",
      "Epoch: 10, Train Loss: 0.2495, Train Acc: 93.30%, Test Loss: 0.3779, Test Acc: 91.59%\n",
      "Epoch: 11, Train Loss: 0.2368, Train Acc: 93.65%, Test Loss: 0.3558, Test Acc: 92.10%\n",
      "Epoch: 12, Train Loss: 0.2355, Train Acc: 93.78%, Test Loss: 0.3541, Test Acc: 92.10%\n",
      "Epoch: 13, Train Loss: 0.2322, Train Acc: 93.66%, Test Loss: 0.3466, Test Acc: 91.87%\n",
      "Epoch: 14, Train Loss: 0.2296, Train Acc: 93.66%, Test Loss: 0.3473, Test Acc: 92.09%\n",
      "Epoch: 15, Train Loss: 0.2345, Train Acc: 93.56%, Test Loss: 0.3438, Test Acc: 92.11%\n",
      "Epoch: 16, Train Loss: 0.2436, Train Acc: 93.29%, Test Loss: 0.3570, Test Acc: 91.66%\n",
      "Epoch: 17, Train Loss: 0.2252, Train Acc: 93.84%, Test Loss: 0.3468, Test Acc: 92.12%\n",
      "Epoch: 18, Train Loss: 0.2380, Train Acc: 93.38%, Test Loss: 0.3549, Test Acc: 91.67%\n",
      "Epoch: 19, Train Loss: 0.2308, Train Acc: 93.49%, Test Loss: 0.3558, Test Acc: 91.47%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nepochs):\n",
    "    scheduler.step()\n",
    "    for bx, by in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(bx)\n",
    "        err = criterion(logit, by)\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    loss_train, acc_train = eval(model, criterion,train_dl)\n",
    "    loss_test, acc_test = eval(model, criterion,test_dl)\n",
    "    print('Epoch: {}, Train Loss: {:.4f}, Train Acc: {:.2f}%, Test Loss: {:.4f}, Test Acc: {:.2f}%'.format(epoch, loss_train, acc_train, loss_test, acc_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
