{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  time\n",
    "\n",
    "import  torch\n",
    "import  torch.nn as nn\n",
    "import  torch.nn.functional as F\n",
    "from    torch.autograd import Variable\n",
    "\n",
    "import  torchvision.datasets as dsets\n",
    "import  torchvision.transforms as trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv5x5(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=stride, padding=2, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "          nn.Conv2d(1,10,5,padding=2),\n",
    "          nn.AvgPool2d(2),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(10,20,5,padding=2),\n",
    "          nn.AvgPool2d(2),\n",
    "          nn.ReLU())\n",
    "        self.classifier = nn.Sequential(\n",
    "          nn.Linear(7*7*20,500),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(500,10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.feature(x)\n",
    "        o = o.view(x.size(0),-1)\n",
    "        o = self.classifier(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=980, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "\n",
    "# 检查是否支持MPS并使用MPS\n",
    "if torch.backends.mps.is_available():\n",
    "    net = net.to('mps')\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_set = dsets.MNIST(root = '../data/',transform=trans.ToTensor(),train=True,download=True)\n",
    "test_set = dsets.MNIST(root='../data/',transform=trans.ToTensor(),train=False)\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "nepochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,criterion,dataloader):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    for batch_x,batch_y in dataloader:\n",
    "        batch_x = Variable(batch_x)\n",
    "        batch_y = Variable(batch_y)\n",
    "        if torch.backends.mps.is_available():\n",
    "            batch_x = batch_x.to('mps')\n",
    "            batch_y = batch_y.to('mps')\n",
    "            \n",
    "        logits = model(batch_x)\n",
    "        error = criterion(logits,batch_y)\n",
    "        loss += error.item()\n",
    "        \n",
    "        probs,pred_y = logits.data.max(dim=1)\n",
    "        accuracy += (pred_y==batch_y.data).sum()/batch_y.size(0)\n",
    "        \n",
    "    loss /= len(dataloader)\n",
    "    accuracy = accuracy*100/len(dataloader)\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/30, 4 sec|\t train loss: 0.3420, train acc: 89.74 |\t  test loss: 0.3325, test acc: 90.18\n",
      " 2/30, 4 sec|\t train loss: 0.2306, train acc: 93.09 |\t  test loss: 0.2176, test acc: 93.54\n",
      " 3/30, 4 sec|\t train loss: 0.1596, train acc: 95.22 |\t  test loss: 0.1502, test acc: 95.57\n",
      " 4/30, 4 sec|\t train loss: 0.1192, train acc: 96.39 |\t  test loss: 0.1132, test acc: 96.58\n",
      " 5/30, 4 sec|\t train loss: 0.0952, train acc: 97.13 |\t  test loss: 0.0901, test acc: 97.31\n",
      " 6/30, 4 sec|\t train loss: 0.0778, train acc: 97.58 |\t  test loss: 0.0742, test acc: 97.61\n",
      " 7/30, 4 sec|\t train loss: 0.0668, train acc: 97.95 |\t  test loss: 0.0653, test acc: 97.86\n",
      " 8/30, 4 sec|\t train loss: 0.0606, train acc: 98.10 |\t  test loss: 0.0619, test acc: 97.98\n",
      " 9/30, 4 sec|\t train loss: 0.0502, train acc: 98.44 |\t  test loss: 0.0521, test acc: 98.20\n",
      "10/30, 4 sec|\t train loss: 0.0444, train acc: 98.67 |\t  test loss: 0.0499, test acc: 98.38\n",
      "11/30, 4 sec|\t train loss: 0.0424, train acc: 98.67 |\t  test loss: 0.0478, test acc: 98.34\n",
      "12/30, 4 sec|\t train loss: 0.0388, train acc: 98.79 |\t  test loss: 0.0482, test acc: 98.40\n",
      "13/30, 4 sec|\t train loss: 0.0355, train acc: 98.94 |\t  test loss: 0.0450, test acc: 98.47\n",
      "14/30, 4 sec|\t train loss: 0.0319, train acc: 99.04 |\t  test loss: 0.0417, test acc: 98.67\n",
      "15/30, 4 sec|\t train loss: 0.0294, train acc: 99.11 |\t  test loss: 0.0445, test acc: 98.54\n",
      "16/30, 4 sec|\t train loss: 0.0275, train acc: 99.17 |\t  test loss: 0.0441, test acc: 98.54\n",
      "17/30, 4 sec|\t train loss: 0.0233, train acc: 99.33 |\t  test loss: 0.0412, test acc: 98.56\n",
      "18/30, 4 sec|\t train loss: 0.0223, train acc: 99.37 |\t  test loss: 0.0411, test acc: 98.59\n",
      "19/30, 4 sec|\t train loss: 0.0189, train acc: 99.48 |\t  test loss: 0.0386, test acc: 98.72\n",
      "20/30, 4 sec|\t train loss: 0.0180, train acc: 99.48 |\t  test loss: 0.0399, test acc: 98.76\n",
      "21/30, 4 sec|\t train loss: 0.0266, train acc: 99.09 |\t  test loss: 0.0504, test acc: 98.47\n",
      "22/30, 4 sec|\t train loss: 0.0194, train acc: 99.43 |\t  test loss: 0.0422, test acc: 98.56\n",
      "23/30, 4 sec|\t train loss: 0.0148, train acc: 99.59 |\t  test loss: 0.0436, test acc: 98.48\n",
      "24/30, 4 sec|\t train loss: 0.0136, train acc: 99.59 |\t  test loss: 0.0398, test acc: 98.71\n",
      "25/30, 4 sec|\t train loss: 0.0110, train acc: 99.73 |\t  test loss: 0.0421, test acc: 98.56\n",
      "26/30, 4 sec|\t train loss: 0.0127, train acc: 99.64 |\t  test loss: 0.0425, test acc: 98.75\n",
      "27/30, 4 sec|\t train loss: 0.0137, train acc: 99.58 |\t  test loss: 0.0476, test acc: 98.61\n",
      "28/30, 4 sec|\t train loss: 0.0113, train acc: 99.68 |\t  test loss: 0.0376, test acc: 98.86\n",
      "29/30, 4 sec|\t train loss: 0.0106, train acc: 99.70 |\t  test loss: 0.0457, test acc: 98.72\n",
      "30/30, 4 sec|\t train loss: 0.0081, train acc: 99.79 |\t  test loss: 0.0411, test acc: 98.69\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nepochs):\n",
    "    since = time.time()\n",
    "    for batch_x,batch_y in train_dl:\n",
    "        batch_x = Variable(batch_x)\n",
    "        batch_y = Variable(batch_y)\n",
    "        if torch.backends.mps.is_available():\n",
    "            batch_x = batch_x.to('mps')\n",
    "            batch_y = batch_y.to('mps')\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        logits = net(batch_x)\n",
    "        error = criterion(logits,batch_y)\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    now = time.time()\n",
    "    train_loss,train_acc = eval(net,criterion,train_dl)\n",
    "    test_loss,test_acc = eval(net,criterion,test_dl)\n",
    "    print('%2d/%d, %.0f sec|\\t train loss: %.4f, train acc: %.2f |\\t  test loss: %.4f, test acc: %.2f' % (epoch+1,nepochs,now-since,train_loss,train_acc,test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
